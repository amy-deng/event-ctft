1. check correlations between riots and protests
2. run simple models to predict riots
3. build cf data 


4. train baseline model. causal inference model. 

5. overlap of data, window and pred window

positive: pred_window=3
IND:0.8318
RUS:0.7009
PAK:0.2895
TUR:0.2757
GBR:0.2895
pred_window=1
IND: 0.5450
RUS: 0.3916

average daily events:
IND 44.97875569044006
RUS 66.62229806598407

afg 33.56610576923077
syria 54.60900900900901
yemen 27.45158597662771

conda activate ctft
python build_label_ICEWS.py RUS 7 4 1
python build_label_ICEWS.py IND 10 3 1

python build_label_ACLED.py /home/sdeng/data/ACLED/country-jul23/2015-01-01-2021-07-23-Yemen.csv 10 3 3
Syria 7 2 3
python build_label_ACLED.py /home/sdeng/data/ACLED/country-jul23/2017-01-01-2021-07-23-Syria.csv 7 5 2

3 top cities (data sparsity of some cities) 
window 7 1 3 
RUS  0.3690
['0.528 0.0', '0.0 0.0', '0.859 0.0', '0.794 0.0', '0.69 0.0', '0.763 0.0', '0.725 0.0']
IND 0.8318
['0.406 0.0', '0.0 0.0', '0.69 0.0', '0.616 0.0', '0.877 0.0', '0.845 0.0', '0.861 0.0']
['0.4 0.0', '0.0 0.0', '0.662 0.0', '0.544 0.0', '0.847 0.0', '0.931 0.0', '0.887 0.0']


window 7 2 3 
RUS 0.3690
['0.473 0.0', '0.0 0.0', '0.833 0.0', '0.757 0.0', '0.669 0.0', '0.699 0.0', '0.683 0.0']
['0.476 0.0', '0.0 0.0', '0.847 0.0', '0.782 0.0', '0.72 0.0', '0.715 0.0', '0.717 0.0']
IND 0.5456 √√√
['0.593 0.0', '0.0 0.0', '0.769 0.0', '0.688 0.0', '0.711 0.0', '0.678 0.0', '0.694 0.0']
['0.618 0.0', '0.0 0.0', '0.781 0.0', '0.692 0.0', '0.748 0.0', '0.615 0.0', '0.675 0.0']
['0.595 0.0', '0.0 0.0', '0.769 0.0', '0.683 0.0', '0.703 0.0', '0.668 0.0', '0.685 0.0']
['0.583 0.0', '0.0 0.0', '0.758 0.0', '0.692 0.0', '0.701 0.0', '0.708 0.0', '0.705 0.0']


window 7 3 3 
RUS 0.3619 
['0.523 0.0', '0.0 0.0', '0.815 0.0', '0.759 0.0', '0.688 0.0', '0.692 0.0', '0.69 0.0']
['0.531 0.0', '0.0 0.0', '0.814 0.0', '0.771 0.0', '0.694 0.0', '0.724 0.0', '0.709 0.0']

IND 0.5483
['0.595 0.0', '0.0 0.0', '0.745 0.0', '0.687 0.0', '0.705 0.0', '0.691 0.0', '0.698 0.0']
['0.604 0.0', '0.0 0.0', '0.733 0.0', '0.676 0.0', '0.693 0.0', '0.648 0.0', '0.67 0.0']
['0.599 0.0', '0.0 0.0', '0.73 0.0', '0.659 0.0', '0.686 0.0', '0.633 0.0', '0.659 0.0']

window 7 4 3 
RUS 0.3672
['0.507 0.0', '0.0 0.0', '0.827 0.0', '0.773 0.0', '0.701 0.0', '0.731 0.0', '0.716 0.0']
['0.513 0.0', '0.0 0.0', '0.82 0.0', '0.79 0.0', '0.708 0.0', '0.764 0.0', '0.735 0.0']
IND 0.5508
['0.582 0.0', '0.0 0.0', '0.742 0.0', '0.69 0.0', '0.747 0.0', '0.64 0.0', '0.69 0.0']
['0.592 0.0', '0.0 0.0', '0.749 0.0', '0.689 0.0', '0.738 0.0', '0.651 0.0', '0.692 0.0']
['0.58 0.0', '0.0 0.0', '0.735 0.0', '0.692 0.0', '0.73 0.0', '0.695 0.0', '0.712 0.0']
['0.588 0.0', '0.0 0.0', '0.736 0.0', '0.677 0.0', '0.726 0.0', '0.638 0.0', '0.679 0.0']

window 7 5 3
RUS 0.3657 √√√
['0.512 0.0', '0.0 0.0', '0.849 0.0', '0.804 0.0', '0.722 0.0', '0.779 0.0', '0.749 0.0']
['0.533 0.0', '0.0 0.0', '0.854 0.0', '0.798 0.0', '0.74 0.0', '0.753 0.0', '0.746 0.0']
['0.513 0.0', '0.0 0.0', '0.859 0.0', '0.803 0.0', '0.727 0.0', '0.776 0.0', '0.751 0.0']
IND 0.5462
['0.576 0.0', '0.0 0.0', '0.743 0.0', '0.664 0.0', '0.708 0.0', '0.628 0.0', '0.666 0.0']
['0.588 0.0', '0.0 0.0', '0.734 0.0', '0.665 0.0', '0.707 0.0', '0.643 0.0', '0.673 0.0']
['0.585 0.0', '0.0 0.0', '0.721 0.0', '0.648 0.0', '0.687 0.0', '0.625 0.0', '0.654 0.0']

window 7 6 3
RUS 0.3624  
['0.544 0.0', '0.0 0.0', '0.833 0.0', '0.777 0.0', '0.724 0.0', '0.724 0.0', '0.724 0.0']
['0.531 0.0', '0.0 0.0', '0.832 0.0', '0.779 0.0', '0.726 0.0', '0.722 0.0', '0.724 0.0']

IND 0.5489
['0.59 0.0', '0.0 0.0', '0.752 0.0', '0.697 0.0', '0.755 0.0', '0.657 0.0', '0.703 0.0']
['0.581 0.0', '0.0 0.0', '0.745 0.0', '0.683 0.0', '0.719 0.0', '0.692 0.0', '0.706 0.0']


window 10 2 2
IND 0.4475
['0.588 0.0', '0.0 0.0', '0.734 0.0', '0.678 0.0', '0.684 0.0', '0.554 0.0', '0.612 0.0']

10 3 2

IND 0.4448
['0.621 0.0', '0.0 0.0', '0.746 0.0', '0.669 0.0', '0.682 0.0', '0.539 0.0', '0.602 0.0']

10 4 2
0.4476
['0.616 0.0', '0.0 0.0', '0.747 0.0', '0.677 0.0', '0.689 0.0', '0.55 0.0', '0.612 0.0']

10 5 2
0.4449
['0.591 0.0', '0.0 0.0', '0.728 0.0', '0.663 0.0', '0.672 0.0', '0.534 0.0', '0.595 0.0']

generate all data .... 

When learning a causal model, one
should, thus, require fewer examples to adapt as most
knowledge, that is, modules, can be reused without further
training.


 discovering 
causal relations means acquiring robust knowledge that
holds beyond the support of observed data distribution
and a set of training tasks, and it extends to situations
involving forms of reasoning.

 causality, with its focus on representing structural knowledge
about the data generating process that allows interventions
and changes, can contribute toward understanding and
resolving some limitations of current machine learning
methods


assume that the words are sufficient for
adjustment.


using different treatment.... auc might be higher

['0.646 0.007', '0.0 0.0', '0.666 0.012', '0.618 0.008', '0.665 0.013', '0.624 0.032', '0.643 0.016']
['0.658 0.017', '0.0 0.0', '0.676 0.017', '0.624 0.01', '0.665 0.021', '0.652 0.043', '0.657 0.02']
['0.688 0.008', '0.0 0.0', '0.668 0.008', '0.62 0.02', '0.668 0.038', '0.644 0.034', '0.654 0.008']

calculate ate for different ...
 
Syria
7-2-2
['0.641 0.0', '0.0 0.0', '0.622 0.0', '0.568 0.0', '0.689 0.0', '0.587 0.0', '0.634 0.0']

7-3-2
['0.589 0.0', '0.0 0.0', '0.692 0.0', '0.626 0.0', '0.661 0.0', '0.741 0.0', '0.699 0.0']
['0.621 0.0', '0.0 0.0', '0.609 0.0', '0.543 0.0', '0.601 0.0', '0.782 0.0', '0.68 0.0']
7-4-2 √√√√√
['0.637 0.0', '0.0 0.0', '0.614 0.0', '0.545 0.0', '0.606 0.0', '0.7 0.0', '0.65 0.0']
['0.648 0.0', '0.0 0.0', '0.652 0.0', '0.641 0.0', '0.695 0.0', '0.732 0.0', '0.713 0.0']

7-5-2
['0.644 0.0', '0.0 0.0', '0.681 0.0', '0.649 0.0', '0.737 0.0', '0.635 0.0', '0.682 0.0']
['0.642 0.0', '0.0 0.0', '0.646 0.0', '0.61 0.0', '0.693 0.0', '0.681 0.0', '0.687 0.0']

Yemen
10-3-2
['0.562 0.0', '0.0 0.0', '0.779 0.0', '0.698 0.0', '0.805 0.0', '0.652 0.0', '0.72 0.0']
['0.527 0.0', '0.0 0.0', '0.762 0.0', '0.71 0.0', '0.846 0.0', '0.611 0.0', '0.71 0.0']

10-4-2√√√
['0.578 0.0', '0.0 0.0', '0.778 0.0', '0.717 0.0', '0.85 0.0', '0.647 0.0', '0.735 0.0']
['0.583 0.0', '0.0 0.0', '0.771 0.0', '0.736 0.0', '0.848 0.0', '0.687 0.0', '0.759 0.0']

10-5-2
['0.531 0.0', '0.0 0.0', '0.754 0.0', '0.708 0.0', '0.806 0.0', '0.667 0.0', '0.73 0.0']
['0.493 0.0', '0.0 0.0', '0.792 0.0', '0.727 0.0', '0.818 0.0', '0.709 0.0', '0.759 0.0']


10-2-2
['0.595 0.0', '0.0 0.0', '0.816 0.0', '0.736 0.0', '0.869 0.0', '0.646 0.0', '0.741 0.0']



######
2001|---------------------------------------------|2017
                            |---|-| 
                            historical information
                            historical event causal information



tokens_list = [['thailand', 'karaoke', 'karaoke', 'owner', 'wounded', 'pattani', 'shooting', 'shooting', 'insurgency', 'deep', 'south', 'continues', 'gun', 'attack', 'injured', 'karaoke', 'shop', 'owner', 'pattani', 'insurgent', 'carried', 'bomb', 'attack', 'district', 'injury', 'reported', 'explosion', 'damaged', 'motorcycle', 'left', 'ban', 'ban', 'bu-sala', 'song', 'road', 'yarang', 'district', 'pattani', 'human', 'casualty', 'reported', 'investigator', 'network'], ['killed', 'thai', 'troubled', 'south', 'people', 'including', 'marine', 'suspected', 'militant', 'killed', 'separate', 'clash', 'thailand', 'violent', 'south', 'police', 'military', 'officer', 'wednesday', 'military', 'security', 'force', 'arrest', 'militant', 'gathering', 'gun', 'thailand']]